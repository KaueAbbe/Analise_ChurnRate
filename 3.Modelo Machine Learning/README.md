![Capa3](https://user-images.githubusercontent.com/68445400/170520115-4fda6530-0a31-403c-a95a-f769ba26d833.jpg)



![Badge em Desenvolvimento](https://img.shields.io/static/v1?label=STATUS&message=DESENVOLVIMENTO&color=<COLOR>)

<h1 align ="center">Resumo dos Resultados</h1>

Realizei a cria√ß√£o de um modelo de classifica√ß√£o que classifica com 81% de Recall os clientes em evasores ou n√£o evasores. Inicei o processo com pr√©-processamento dos dados, fazendo encoding, balanceamento e normalizando. Separei os dados para treinar, testar e validar o modelo. Foi criado baseline e utilizado FeatureImportances para determinar quais features importam na classifica√ß√£o. Seis modelos de classifica√ß√£o foram treinados e testados, utilizando Recall e m√©trica de Bussines como fator de decis√£o. Ap√≥s, dois modelos passaram pelo processo de otimiza√ß√£o por Hiperpar√¢metros, e o melhor modelo foi verificado com 81% de Recall e 6% de perda clientes evasores.

<h1 align ="center">Discuss√£o dos Resultados</h1>

<h2 align= "Left"> 1 . Pr√©-processamento</h2>

O pr√©-processamento contou com uma sequ√™ncia de passo para organizar e preparar os dados para a cria√ß√£o do modelo. Foram os passos:
1. Tradu√ß√£o de Valores bin√°rios do tipo string para bin√°rios do tipo num√©ricos. *sim -> 1* e *n√£o -> 0*. Usei m√©todo *Replace do Pandas*.
2. Label Encoding dos dados qualitativos com mais de tr√™s valores. Usei o m√©todo *Get_dummies do Pandas*.
3. Balanceei os dados usando OverSampler para melhorar o treinamento e n√£o perder dados. O m√©todo usando foi *RandomOverSampler do imblearn*
4. Normaliza√ß√£o os dados quantitativos de gastos e tempo de contrato. Usei m√©todo *StandardScaler do Sklear*

<h2 align= "Left"> 2 . Separa√ß√£o de Dados </h2>

A separa√ß√£o de dados foi feita de forma que fosse poss√≠vel realizar o treinamento do modelo, testagem e valida√ß√£o. Abaixo explico qual momento usei os quais dataset.
1. Dados treino foram usados em todos treinamentos de modelos, usando 80% do dataset original.
2. Dados de Teste foram usados para testar perfomace dos modelos ap√≥s treinamento. Usei 15% do dataset original.
3. Dados de Valida√ß√£o foram usados para validar a performace do modelo final otimizado. Usei 5% do dataset original

<h2 align= "Left"> 3 . M√©tricas Escolhidas </h2>

A m√©trica escolhidas foram duas: Recall e M√©trica de Bussines. Explico a escolha e funcionamento das duas abaixo.
1. **Recall:** O recall foi escolhido pois √© a m√©trica que retonar o qu√£o correto o modelo classifica os clientes como evasores, j√° que estou trabalhando numa situa√ß√£o em que o objetivo √© a diminui√ß√£o da evas√£o dos clientes, e por isso √© importante conhecer corretamente qual cliente ir√° evadir.
2. **M√©trica de Bussines:** Nesta m√©trica retorna o objetivo de diminuir a evas√£o dos clientes, calculando qual a perda da empresa em classificar um cliente como n√£o evasor erroneamente. Esta m√©trica calcula a taxa de perda de clientes por classificar erroneamente como n√£o evasor.


<h2 align= "Left"> 4 . Baseline e Feature Importances </h2>

Duas baselines foram criadas: DummyClassifier e LogisticRegression. Porque o dummy classifica com aleatoriedade, usei como baseline principal o LogisticRegression: Uma base 78% de Recall e 20% de perda foi criada. 

O Feature Importances, da biblioteca YellowBrick, foi usado para avaliar quais features tem maior magnitude na classifica√ß√£o. Retirei features com menor import√¢ncia e refiz a cria√ß√£o do modelo LogisticRegression, e como n√£o houve diferen√ßa utilizei o treinamento dos dados com todas as features.

<h2 align= "Left"> 5 . Treinamento de Modelos </h2

Seis modelos de classifica√ß√£o foram treinados e avalidados com base nas m√©tricas: DecisionTree, AdaBoost, BernoulliNB, SVC, RandomForest e GradientBoost. Todos os modelos foram treinado usando Cross_validation, com *Cross_validation* e *KFold*.
De acordo com os resultados das m√©tricas dois modelos seguiram para o processo de otimiza√ß√£o: *RandomForest e GradientBoost*

<h2 align= "Left"> 6 . Otimiza√ß√£o dos Modelos</h2

A otimiza√ß√£o dos dois modelo escolhidos foi feita com o GridSearchCV para buscar a melhor combina√ß√£o de hiperpar√¢metros. O processo foi feita algumas vezes. Al√©m da extensa busca pelos hiperpar√¢metros, fiz a testagem da melhor combina√ß√£o usando *cross_val_score*. Tamb√©m usei a matriz confus√£o para avaliar diferen√ßas espec√≠ficas nas classifica√ß√µes. 
Entre os dois modelos otimizados o melhor foi **RandomForest**

<h2 align= "Left"> 7 . Valida√ß√£o e Salvar o modelo</h2

A valida√ß√£o foi feita com dados de valida√ß√£o, sob o modelo otimizado com Hiperpar√¢metros encontrado. O resultado foi salvo utilizando Pickle. 
O modelo Final cont√©m: Recall: 81% e Perda de Cliente: 6%.


<h2 align= "Center">Conclus√£o</h2>

Portanto, apresentei aqui os resultados da cria√ß√£o de um modelo de machine learing que classifica cliente em evasores ou n√£o, com 81% de certeza em classificar como evasor e perda de 6% classificando errado como n√£o evasor. O processo de cria√ß√£o contou com diversos m√©todos que contribuiram no label encoding, balanceamento, normaliza√ß√£o. Dados foram separados para treinar, testar e validar o modelo durante a cria√ß√£o. Com o foco em diminuir os clientes evasores, como m√©trica utilizei o Recall e uma m√©trica de Bussines criada para diminuir perdas da empresas. A otimiza√ß√£o e a valida√ß√£o concluiu um modelo com 81% de certeza em classificar como evasor e perda de 6% classificando errado como n√£o evasor 

Com este modelo a empresa pode classificar os clientes em evasores ou n√£o evasores, contribuindo com a tomada de decis√£o quanto a quais clientes focar suas estrat√©gias de diminui√ß√£o de Churn. 



<h2 align ="center"> Quais bibliotecas foram usadas?</h2>
1. Para ler e tratar os dados: Pandas üêº |
2. Matem√°tica: Numpy |
3. Fazer os Modelos e Avalia-los: Sklearn |
4. FeatureImportances: YellowBrick |
5. Salvar Modelo: Pickle |












